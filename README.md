# STAT496Capstone

By: Arnav Palkhiwala, Mohit Mohanraj, Maxx Ferrian

<h2> Research Topic: </h2>

- Judging how LLMs respond to judging multiple pieces of writing (such as resumes or essays) based on order, as well as the inputs in the prompt (examples for few-shot or zero-shot prompting)
- Pick 1-3 domains: essays, resumes, technical docs 
- 3 examples (vary/choose the number of positive and negative ones) for each domain for the prompt input
- Then use a large number of ‘unjudged’ papers 
- Create a rubric for grading and provide it in the input
- LLM output will be a score on a scale of 1-10

<h2> What are we testing for (ONLY changing one at a time)?: </h2>

- Order - does the order in which the resumes/essays are submitted impact how they’re scored?
- LLM Quality Eval - can an LLM accurately score and understand the quality of the input with and without examples? (Zero vs. Few-Shot Prompting)



